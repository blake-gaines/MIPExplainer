{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import get_dataset\n",
    "from gnn import GNN # noqa: F401\n",
    "from pyvis.network import Network\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch_geometric.datasets.graph_generator import ERGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"MUTAG\"\n",
    "# model_path = \"models/MUTAG_model_new.pth\"\n",
    "# dataset_name = \"ENZYMES\"\n",
    "# model_path = \"models/ENZYMES_model.pth\"\n",
    "# dataset_name = \"Shapes_Ones\"\n",
    "# model_path = \"models/Shapes_Ones_model.pth\"\n",
    "dataset_name = \"MNISTSuperpixels\"\n",
    "model_path = \"models/MNISTSuperpixels_model.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "nn = torch.load(model_path, fix_imports=True, map_location=device)\n",
    "nn.device = device\n",
    "nn.to(device)\n",
    "nn.eval()\n",
    "dataset = get_dataset(dataset_name)\n",
    "train_loader = dataset.get_train_loader()\n",
    "test_loader = dataset.get_test_loader()\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_random_class = True\n",
    "\n",
    "if add_random_class:\n",
    "    all_data = list(dataset.data)\n",
    "    for i in tqdm(range(len(all_data)//5)):\n",
    "        generator = ERGraph(75, 0.2)\n",
    "        data = generator()\n",
    "        data.x = torch.eye(dataset.num_node_features)[np.random.randint(0, dataset.num_node_features, (data.num_nodes,))]\n",
    "        data.y = torch.tensor(dataset.num_classes)\n",
    "        all_data.append(data)\n",
    "    dataset.data = all_data\n",
    "    dataset.num_classes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relu_activations(nn, data, threshold=0):\n",
    "    all_outputs = nn.get_all_layer_outputs(data)\n",
    "    output_vector = torch.concat([o[1].flatten() for o in all_outputs if \"Relu\" in o[0] and \"Lin\" in o[0]])\n",
    "    return output_vector.squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_numel = [output.numel() for name, output in nn.get_all_layer_outputs(next(iter(train_loader))[0]) if \"Relu\" in name and \"Lin\" in name]\n",
    "mask_end_indices = dict(zip([name for name in nn.layers.keys() if \"Relu\" in name and \"Lin\" in name], np.cumsum(out_numel)))\n",
    "mask_end_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = mask_end_indices[\"Lin_1_Relu\"], mask_end_indices[\"Lin_2_Relu\"]\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame()\n",
    "a[\"data\"] = list(dataset.data)\n",
    "a[\"y\"] = a[\"data\"].apply(lambda x: x.y if isinstance(x.y, int) else x.y.item())\n",
    "a[\"num_nodes\"] = a[\"data\"].apply(lambda x: x.num_nodes)\n",
    "a[\"num_edges\"] = a[\"data\"].apply(lambda x: x.num_edges)\n",
    "tqdm.pandas(desc=\"Gathering ReLU Outputs\")\n",
    "a[\"selected_activations\"] = a[\"data\"].progress_apply(lambda x: get_relu_activations(nn, x)[start:end])\n",
    "a[\"output\"] = a[\"data\"].apply(lambda x: nn(x).detach().numpy().flatten())\n",
    "a[\"prediction\"] = a[\"output\"].apply(lambda x: np.argmax(x))\n",
    "a[\"correct\"] = a[\"prediction\"] == a[\"y\"]\n",
    "a[a[\"y\"]==dataset.num_classes-1][\"correct\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "a[\"mask\"] = a[\"selected_activations\"].apply(lambda x: (x > threshold).astype(int))\n",
    "\n",
    "masks = np.stack(a[\"mask\"].tolist())\n",
    "unique_masks, unique_inverse, unique_counts = np.unique(masks, axis=0, return_index=False, return_inverse=True, return_counts=True) \n",
    "print(\"Masks Shape:\", masks.shape)\n",
    "print(\"Unique Masks Shape:\", unique_masks.shape)\n",
    "print(\"Unique Inverse Shape:\", unique_inverse.shape)\n",
    "print(\"Unique Counts Shape:\", unique_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_df = pd.DataFrame()\n",
    "mask_df[\"mask\"] = list(unique_masks)\n",
    "mask_df[\"tuple\"] = mask_df[\"mask\"].apply(tuple)\n",
    "mask_df[\"count\"] = unique_counts.tolist()\n",
    "mask_df[\"indices\"] = mask_df.index.map(lambda x: np.argwhere(unique_inverse == x))\n",
    "mask_df[\"correct_proportion\"] = mask_df[\"indices\"].apply(lambda x: np.mean(a[\"correct\"].values[x]).item())\n",
    "mask_df[\"ys\"] = mask_df[\"indices\"].apply(lambda x: np.atleast_1d(a[\"y\"].values[x].squeeze()))\n",
    "mask_df[\"predictions\"] = mask_df[\"indices\"].apply(lambda x: np.atleast_1d(a[\"prediction\"].values[x].squeeze()))\n",
    "mask_df[\"confusion_matrix\"] = mask_df.apply(lambda x: confusion_matrix(x[\"ys\"], x[\"predictions\"], labels=np.arange(dataset.num_classes)), axis=1)\n",
    "mask_df[\"class_proportions\"] = mask_df[\"ys\"].apply(lambda x: np.bincount(x, minlength=dataset.num_classes) / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(mask_df, x=\"count\", nbins=100, title=\"Instances Per Mask\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.draw_graph(data=dataset.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diff = 1\n",
    "subset=mask_df\n",
    "num_masks = len(subset)\n",
    "# subset = mask_df[mask_df[\"count\"]>1]\n",
    "# num_masks = min(num_masks, len(subset))\n",
    "# subset = subset.sample(num_masks, random_state=0)\n",
    "\n",
    "G = nx.Graph()\n",
    "bar = tqdm(subset.iterrows(), total=num_masks)\n",
    "for i, row in bar:\n",
    "    # num_examples = min(len(row[\"indices\"]), 4)\n",
    "    # num_rows = np.ceil(np.sqrt(num_examples)).astype(int)\n",
    "    # num_cols = num_examples // num_rows\n",
    "    # fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "    # axs = axs.flatten() if num_rows > 1 else [axs]\n",
    "    # for j, ax in enumerate(axs):\n",
    "    #     ax.axis(\"equal\")\n",
    "    #     ax.set_axis_off()\n",
    "    #     if j <= num_examples:\n",
    "    #         data = a[\"data\"].values[row[\"indices\"][j][0]]\n",
    "    #         dataset.draw_graph(data=data, ax=ax)\n",
    "\n",
    "    # fig, ax = dataset.draw_graph(data=dataset.data[row[\"indices\"][0][0]])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.margins(0,0)\n",
    "    ax.pie(row[\"class_proportions\"], labeldistance=.6, labels = list(range(dataset.num_classes)))\n",
    "    ax.set_box_aspect(1)\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "    plt.tight_layout(pad=0)\n",
    "    fig.canvas.draw()\n",
    "    img = Image.frombytes(\n",
    "        \"RGBa\", fig.canvas.get_width_height(), fig.canvas.buffer_rgba()\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    img.convert(\"RGB\").resize((30,30)).save(f\"images/{i}.png\")\n",
    "\n",
    "    title = f\"Mask {i}\\n{row['count']} sample{'s' if row['count']>1 else ''}\\nCorrect Proportion: {row['correct_proportion']:.2f}\"\n",
    "    title += ''.join(f\"\\nClass {i} Proportion: {p:.2f}\" for i, p in enumerate(row[\"class_proportions\"]))\n",
    "    cm = '\\n'.join(str(row) for row in row[\"confusion_matrix\"].tolist())\n",
    "    title += f\"\\nConfusion Matrix:\\n{cm}\"\n",
    "    label = f\"Mask {i}\"\n",
    "    G.add_node(row[\"tuple\"], title=title, label=label, count=row[\"count\"], image =f\"images/{i}.png\", shape=\"image\", size=10*(np.log(row['count'])+3))\n",
    "    for other_node in G.nodes:\n",
    "        difference = np.nonzero(row[\"mask\"] ^ other_node)[0]\n",
    "        bits_different = len(difference)\n",
    "        if 0 < bits_different <= max_diff:\n",
    "            title = f\"# Bits Different: {bits_different}\\nDifference: {str(difference.tolist())}\"\n",
    "            G.add_edge(row[\"tuple\"], other_node, title=title, value=1/bits_different)\n",
    "        # G.add_edge(mask_tuple, other_node, weight=bits_different)\n",
    "    bar.set_postfix({\"Nodes\": G.number_of_nodes(), \"Edges\": G.number_of_edges()})\n",
    "G = nx.relabel_nodes(G, {node: str(node) for node in G.nodes}, copy=False)\n",
    "print(f\"Number of Nodes: {G.number_of_nodes()}\\nNumber of Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = Network(height=\"1000px\", width=\"100%\")\n",
    "nt.from_nx(G)\n",
    "nt.show_buttons()\n",
    "# nt.repulsion(node_distance=300, central_gravity=0.2, spring_length=200, spring_strength=0.05)\n",
    "nt.save_graph('nx.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
